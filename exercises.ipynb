{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7ef8962f",
      "metadata": {},
      "source": [
        "<font color='darkred'> Unless otherwise noted, **this notebook will not be reviewed or autograded.**</font> You are welcome to use it for scratchwork, but **only the files listed in the exercises will be checked.**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd72ad2d",
      "metadata": {},
      "source": [
        "# Background\n",
        "\n",
        "Before we move into the exercises, we'll cover some background information to get you started."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b2229a9e",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad8d8983-a06e-4589-b8c8-d4ac8cac7919",
      "metadata": {
        "id": "ad8d8983-a06e-4589-b8c8-d4ac8cac7919"
      },
      "source": [
        "## Markov Chain Simple Example"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f605a922-f2b5-455f-ba19-e695a16ad1ea",
      "metadata": {
        "id": "f605a922-f2b5-455f-ba19-e695a16ad1ea"
      },
      "source": [
        "Markov chains are a way of representing how systems change over time. The main concept behind Markov chains are that they are memoryless, meaning that the next state of a process only depends on the previous state."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43a97067-1056-4622-8e08-03484625df99",
      "metadata": {
        "id": "43a97067-1056-4622-8e08-03484625df99"
      },
      "source": [
        "![image](https://upload.wikimedia.org/wikipedia/commons/7/7a/Markov_Chain_weather_model_matrix_as_a_graph.png)\n",
        "\n",
        "The way to read the Markov chain above from [Wikipedia](https://commons.wikimedia.org/w/index.php?curid=25300524) is:\n",
        "* If I am currently in the sunny state, there is a 10% chance I will go to the rainy state and a 90% chance I will remain in the sunny state\n",
        "* If I am currently in the rainy state, there is an 50% chance I will go to the sunny state and a 50% chance I will remain in the rainy state"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c054964-eacf-4fc8-a9fc-f025dfd1f4fc",
      "metadata": {
        "id": "1c054964-eacf-4fc8-a9fc-f025dfd1f4fc"
      },
      "source": [
        "## Transition Matrices"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87016bb8-9079-4d08-8580-fd1e4d9f7e5e",
      "metadata": {
        "id": "87016bb8-9079-4d08-8580-fd1e4d9f7e5e"
      },
      "source": [
        "This is what our **transition matrix** will look like for the Markov chain diagram above. Take a minute to interpret the rows and columns of this matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "71a600a6-85d4-488a-bcaf-6c3a5ce3079a",
      "metadata": {
        "id": "71a600a6-85d4-488a-bcaf-6c3a5ce3079a",
        "outputId": "fd498834-71a1-4835-f02a-0a8ee68d00eb",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sunny</th>\n",
              "      <th>rainy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>sunny</th>\n",
              "      <td>0.9</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rainy</th>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       sunny  rainy\n",
              "sunny    0.9    0.1\n",
              "rainy    0.5    0.5"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "P = np.asarray([.9, .1, .5, .5]).reshape(2,2)\n",
        "states = ['sunny', 'rainy']\n",
        "\n",
        "pd.DataFrame(P, index=states, columns=states)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c6f5cef-fb28-4d0e-b95d-c7c36aa3eb8b",
      "metadata": {
        "id": "5c6f5cef-fb28-4d0e-b95d-c7c36aa3eb8b"
      },
      "source": [
        "## Predict Tomorrow's Weather"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fda2172-64b6-443f-afe4-d9848662d942",
      "metadata": {
        "id": "1fda2172-64b6-443f-afe4-d9848662d942"
      },
      "source": [
        "Let's say it's sunny today, we can represent that as:\n",
        "\n",
        "`today = [1, 0]`\n",
        "\n",
        "**Predict tomorrow's weather using what you know about today and the transition matrix.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "512bdce6-4a18-445f-b261-cde15113e3fa",
      "metadata": {
        "id": "512bdce6-4a18-445f-b261-cde15113e3fa",
        "outputId": "c3bcde01-b776-4212-ff9a-1def9171cb9e",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.9, 0.1])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "today = [1, 0]\n",
        "\n",
        "tomorrow = np.dot(today, P)\n",
        "tomorrow"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3a8e34c-9387-4859-8728-5cc55229fffb",
      "metadata": {
        "id": "a3a8e34c-9387-4859-8728-5cc55229fffb"
      },
      "source": [
        "In this example, there is a 90% chance it will remain sunny tomorrow, and a 10% chance it'll be rainy."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4909b3a0-5457-4fd3-b384-8854c3e2067d",
      "metadata": {
        "id": "4909b3a0-5457-4fd3-b384-8854c3e2067d"
      },
      "source": [
        "**Predict the day after tomorrow's weather.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5b89f0dd-dd88-4e12-a346-2b636e440ecf",
      "metadata": {
        "id": "5b89f0dd-dd88-4e12-a346-2b636e440ecf",
        "outputId": "f7b6c51d-0958-4157-adba-e47c618f5243",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.86, 0.14])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Method 1: Multiply tomorrow's weather by the transition matrix\n",
        "day_after = np.dot(tomorrow, P)\n",
        "day_after"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "41380f5b-1e86-41dd-bbc0-e7ddfaab06d2",
      "metadata": {
        "id": "41380f5b-1e86-41dd-bbc0-e7ddfaab06d2",
        "outputId": "c137720a-4503-446b-fa55-8e39d27c7455",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.86, 0.14])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Method 2: Multiply today's weather by the transition matrix^2\n",
        "day_after = np.dot(today, np.linalg.matrix_power(P, 2))\n",
        "day_after"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1d3f76b-f595-4c13-9a89-0cbd48349c36",
      "metadata": {
        "id": "b1d3f76b-f595-4c13-9a89-0cbd48349c36"
      },
      "source": [
        "## Text Generation\n",
        "\n",
        "Markov chains can also be used for very basic text generation. **Think about every word in a corpus as a state.** We can make a simple assumption that the next word is only dependent on the previous word - which is the basic assumption of a Markov chain. In this exercise, you'll create a text generator which uses only this concept."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "820d3fd0-8987-4c33-80ee-41e5586daee1",
      "metadata": {
        "id": "820d3fd0-8987-4c33-80ee-41e5586daee1"
      },
      "source": [
        "## Read in some text to imitate"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e1d3d75-fd70-407e-a517-ed9457280d37",
      "metadata": {
        "id": "5e1d3d75-fd70-407e-a517-ed9457280d37"
      },
      "source": [
        "We are going to generate some text in the style of inspirational quotes, so let's first read in the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0ee57df9-dd76-413f-be7b-c102b3ec19bf",
      "metadata": {
        "id": "0ee57df9-dd76-413f-be7b-c102b3ec19bf",
        "outputId": "c93e3469-e6f4-4153-a3c8-a7b26edd6ea3",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ÄúHealing comes from taking responsibility: to realize that it is you - and no one else - that creates your thoughts, your feelings, and your actions.‚Äù ‚ÄîPeter Shepherd\n",
            "\n",
            "‚ÄúLife is a journey and if you fall in love with the journey you will be in love forever.‚Äù ‚ÄîPeter Hagerty\n",
            "\n",
            "‚ÄúWhen you return to your old hometown, you find it wasn‚Äôt the town you missed, but your childhood.‚Äù ‚ÄîEarl Wilson\n",
            "\n",
            "‚ÄúAs we grow old, the beauty steals inward.‚Äù ‚ÄîRalph Waldo Emerson\n",
            "\n",
            "‚ÄúLife begins as a quest of the child for the man, and ends as a journey by the man to rediscover the child.‚Äù ‚ÄîSam Ewing\n",
            "\n",
            "Happiness\n",
            "‚ÄúUltimately your greatest teacher is to live with an open heart.‚Äù ‚ÄîEmmanuel (Pat Rodegast)\n",
            "\n",
            "‚ÄúDoing what you like is freedom. Liking what you do is happiness.‚Äù ‚ÄîFrank Tyger\n",
            "\n",
            "‚ÄúWe forge the chains we wear in life.‚Äù ‚ÄîCharles Dickens\n",
            "\n",
            "happiness quote\n",
            "‚ÄúIf you look to others for fulfillment, you will never be fulfilled. If your happiness depends on money, you will never be happy with yourself. Be content with what you \n"
          ]
        }
      ],
      "source": [
        "url = 'https://raw.githubusercontent.com/leontoddjohnson/datasets/main/text/inspiration_quotes.txt'\n",
        "\n",
        "content = requests.get(url)\n",
        "quotes_raw = content.text\n",
        "\n",
        "print(quotes_raw[:1000])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1e02773-dd1a-407c-ba2a-b01990f03f03",
      "metadata": {
        "id": "c1e02773-dd1a-407c-ba2a-b01990f03f03"
      },
      "source": [
        "## Clean up the text data\n",
        "\n",
        "There are many ways to clean up data before building a text generator. In this case, we'll try to at least just extract the quotes themselves.\n",
        "\n",
        "*After you complete the exercises, feel free to adjust this section of the process ...*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "30a249e9-0207-41e9-ac53-f5b538604fec",
      "metadata": {
        "id": "30a249e9-0207-41e9-ac53-f5b538604fec",
        "outputId": "66c5953b-e28a-4d30-958e-a7a87a4a2801",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['',\n",
              " 'Healing comes from taking responsibility: to realize that it is you - and no one else - that creates your thoughts, your feelings, and your actions.',\n",
              " ' ‚ÄîPeter Shepherd  ']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "quotes = quotes_raw.replace('\\n', ' ')\n",
        "quotes = re.split(\"[‚Äú‚Äù]\", quotes)   # split on the unique ‚Äú characters\n",
        "quotes[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d741a9bf-1e8f-4138-aa0c-a250db1d2e53",
      "metadata": {
        "id": "d741a9bf-1e8f-4138-aa0c-a250db1d2e53",
        "outputId": "a11cd189-dbea-46d4-c255-636dad91ccc0",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Healing comes from taking responsibility: to realize that it is you - and no one else - that creates your thoughts, your feelings, and your actions.',\n",
              " 'Life is a journey and if you fall in love with the journey you will be in love forever.',\n",
              " 'When you return to your old hometown, you find it wasn‚Äôt the town you missed, but your childhood.']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# skip the first one, and capture every other element\n",
        "quotes = quotes[1::2]\n",
        "quotes[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "fac9adc7-5b5c-449c-8a85-a011f14bce8a",
      "metadata": {
        "id": "fac9adc7-5b5c-449c-8a85-a011f14bce8a",
        "outputId": "a8b32ad0-56b8-4140-8790-23c181a949bc",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Healing comes from taking responsibility: to realize that it is you - and no one else - that creates your thoughts, your feelings, and your actions. Life is a journey and if you fall in love with the '"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create one long corpus of text\n",
        "corpus = ' '.join(quotes)\n",
        "\n",
        "# remove long whitespaces (see regex101.com)\n",
        "corpus = re.sub(r\"\\s+\", \" \", corpus)\n",
        "\n",
        "# remove leading/trailing whitespaces\n",
        "corpus = corpus.strip()\n",
        "\n",
        "corpus[:200]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NPc3-Aw7_x_m",
      "metadata": {
        "id": "NPc3-Aw7_x_m"
      },
      "source": [
        "In general, this version of `corpus` should work just fine!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce7213c9-fcea-47f2-a7d3-5dfeb14a0a42",
      "metadata": {
        "id": "ce7213c9-fcea-47f2-a7d3-5dfeb14a0a42"
      },
      "source": [
        "# Exercises\n",
        "\n",
        "In these exercises, you'll build a `MarkovText` object that takes in a `corpus` of text, and has the capability to generate text using the Markov Property."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "08914de7",
      "metadata": {},
      "outputs": [],
      "source": [
        "from apputil import *"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7be36ce-4a51-410f-a0f9-138dfbaf1f2a",
      "metadata": {
        "id": "b7be36ce-4a51-410f-a0f9-138dfbaf1f2a"
      },
      "source": [
        "## Exercise 1: Build a Transition Dictionary"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a386cbbf-abdc-4f6e-bfb3-30988459f37e",
      "metadata": {
        "id": "a386cbbf-abdc-4f6e-bfb3-30988459f37e"
      },
      "source": [
        "Update the `get_term_dict` method to build a term dictionary of Markov states with the following traits:\n",
        "\n",
        "* The keys should be (unique) tokens in the corpus\n",
        "* For each key, the value should be a `list` of all the tokens that follow that key\n",
        "    - E.g., if my total corpus is \"Astrid is very kind, is she not?\", then my dictionary should include `{... \"is\": [\"very\", \"she\"] ...}`.\n",
        "    - Decide whether or not to include duplicates (i.e., *every* iteration) in these lists. Then, explain why or why not.\n",
        "\n",
        "*Hint: You'll likely want to use [`defaultdict(list)`](https://realpython.com/python-defaultdict/#understanding-the-python-defaultdict-type) here.*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1eb4a8cb-4af2-40da-b873-8637a5e0990e",
      "metadata": {
        "id": "1eb4a8cb-4af2-40da-b873-8637a5e0990e"
      },
      "source": [
        "Apply the function to the quotes above. Your final output should look something like this:\n",
        "    \n",
        "```python\n",
        "{\n",
        "    'Healing': ['comes'],\n",
        "    'comes': ['from', 'the', 'the', ...],\n",
        "    'from': ['taking', 'aesthetic', 'a'],\n",
        "    ...\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "8353b120",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample entries from term dictionary:\n",
            "'Healing': ['comes']...\n",
            "'comes': ['from', 'from']...\n",
            "'from': ['taking', 'aesthetic', 'a', 'having', 'not']...\n",
            "'taking': ['responsibility:', 'it.']...\n",
            "'responsibility:': ['to']...\n",
            "\n",
            "Total unique words in dictionary: 994\n",
            "Dictionary built successfully: True\n"
          ]
        }
      ],
      "source": [
        "# Test the implementation\n",
        "text_gen = MarkovText(corpus)\n",
        "\n",
        "# First, let's build and examine the term dictionary\n",
        "term_dict = text_gen.get_term_dict()\n",
        "\n",
        "# Show some sample entries\n",
        "print(\"Sample entries from term dictionary:\")\n",
        "sample_keys = list(term_dict.keys())[:5]\n",
        "for key in sample_keys:\n",
        "    print(f\"'{key}': {term_dict[key][:5]}...\")  # Show first 5 following words\n",
        "\n",
        "print(f\"\\nTotal unique words in dictionary: {len(term_dict)}\")\n",
        "print(f\"Dictionary built successfully: {text_gen.term_dict is not None}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d82c2ca-357d-4115-9b53-b588c6628a14",
      "metadata": {
        "id": "3d82c2ca-357d-4115-9b53-b588c6628a14"
      },
      "source": [
        "## Exercise 2: Create a text generator\n",
        "\n",
        "Update the `generate()` method to generate sentences using the Markov property.\n",
        "\n",
        "- This should use the `.term_dict`, and it should take in the number of terms you want generated, `term_count`.\n",
        "- Your function should also be able to accept an *optional* user-defined `seed_term` that starts the generator. By default, you can have the function select a random first token.\n",
        "  - If the user-defined seed term is not in the corpus, raise a `ValueError`.\n",
        "- Each \"next word\" should be chosen *at random* given the \"current\" word and the term dictionary.\n",
        "  - Consider [`numpy.random.choice`](https://numpy.org/doc/stable/reference/random/generated/numpy.random.choice.html) for this.\n",
        "\n",
        "*Hint: think about what happens if the last term in the corpus occurs only **once**.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "2cd130b1",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'away and watch your wagon to the world‚Äôs a game, play it. Life is the'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_gen.generate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "77c48710",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Testing Exercise 2: Text Generation ===\n",
            "\n",
            "1. Random start (15 words):\n",
            "peace for your childhood. As long at the town you joy. The Nobel. Oscars. The\n",
            "\n",
            "2. Starting with 'life' (20 words):\n",
            "life by creditors or tidy a station you will be loved - it is taking responsibility: to your dysfunction. Life\n",
            "\n",
            "3. Starting with 'happiness' (12 words):\n",
            "happiness that we go, or loving. The need to prove their gifts.\n",
            "\n",
            "4. Testing error handling with invalid seed:\n",
            "‚úì Correctly caught error: Seed term 'invalidword' not found in corpus\n",
            "\n",
            "5. Short generation (5 words):\n",
            "‚Äòout there,‚Äô stop yourself. Be\n"
          ]
        }
      ],
      "source": [
        "# Test more comprehensive generation\n",
        "print(\"=== Testing Exercise 2: Text Generation ===\")\n",
        "print()\n",
        "\n",
        "# Test 1: Random start, default length\n",
        "print(\"1. Random start (15 words):\")\n",
        "print(text_gen.generate())\n",
        "print()\n",
        "\n",
        "# Test 2: Custom seed word\n",
        "print(\"2. Starting with 'life' (20 words):\")\n",
        "try:\n",
        "    result = text_gen.generate(seed_term=\"life\", term_count=20)\n",
        "    print(result)\n",
        "except ValueError as e:\n",
        "    print(f\"Error: {e}\")\n",
        "print()\n",
        "\n",
        "# Test 3: Different seed word\n",
        "print(\"3. Starting with 'happiness' (12 words):\")\n",
        "try:\n",
        "    result = text_gen.generate(seed_term=\"happiness\", term_count=12)\n",
        "    print(result)\n",
        "except ValueError as e:\n",
        "    print(f\"Error: {e}\")\n",
        "print()\n",
        "\n",
        "# Test 4: Error handling - invalid seed\n",
        "print(\"4. Testing error handling with invalid seed:\")\n",
        "try:\n",
        "    result = text_gen.generate(seed_term=\"invalidword\")\n",
        "    print(result)\n",
        "except ValueError as e:\n",
        "    print(f\"‚úì Correctly caught error: {e}\")\n",
        "print()\n",
        "\n",
        "# Test 5: Short generation\n",
        "print(\"5. Short generation (5 words):\")\n",
        "print(text_gen.generate(term_count=5))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09c151e8-2ee4-4b16-9590-eb44ef342f58",
      "metadata": {
        "id": "09c151e8-2ee4-4b16-9590-eb44ef342f58"
      },
      "source": [
        "*Note: this exercise illustrates both a Markov Chain (with constant transition probabilities) **and** a [Monte Carlo Simulation](https://en.wikipedia.org/wiki/Monte_Carlo_method) (iterative sampling from a constantly defined probability distribution of words)!*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a00abc1b",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Bonus Exercise\n",
        "\n",
        "*<font color='darkorange'>The following exercise is completely optional</font>, and will not be reviewed unless explicitly requested. That said, these are interesting to work on if you have the time!*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "182bbcb9",
      "metadata": {},
      "source": [
        "Adjust your text generator such that we can increase the \"state window size\" from one word to `k` words. That is, the term dictionary in this version with `k = 2` would look something like this (*note the tuple keys*):\n",
        "\n",
        "```python\n",
        "{\n",
        "    (\"Healing\", \"comes\"): [\"from\", ...],\n",
        "    ...,\n",
        "    (\"it\", \"is\"): [\"you\", \"very\"],\n",
        "    ...\n",
        "}\n",
        "```\n",
        "\n",
        "Generate some text for `k` values of 1, 2, and 3, and compare the differences in text coherence. Try larger corpuses ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "6519edb3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Enhanced MarkovText class with k-word state windows\n",
        "class EnhancedMarkovText(object):\n",
        "    \n",
        "    def __init__(self, corpus, k=1):\n",
        "        \"\"\"\n",
        "        Initialize the enhanced Markov text generator.\n",
        "        \n",
        "        Parameters:\n",
        "        - corpus: text corpus for training\n",
        "        - k: state window size (number of words to use as state)\n",
        "        \"\"\"\n",
        "        self.corpus = corpus\n",
        "        self.k = k\n",
        "        self.term_dict = None\n",
        "    \n",
        "    def get_term_dict(self):\n",
        "        \"\"\"\n",
        "        Build a transition dictionary with k-word states.\n",
        "        \n",
        "        For k=1: {\"word\": [\"next1\", \"next2\", ...]}\n",
        "        For k=2: {(\"word1\", \"word2\"): [\"next1\", \"next2\", ...]}\n",
        "        For k=3: {(\"word1\", \"word2\", \"word3\"): [\"next1\", \"next2\", ...]}\n",
        "        \"\"\"\n",
        "        from collections import defaultdict\n",
        "        \n",
        "        term_dict = defaultdict(list)\n",
        "        tokens = self.corpus.split()\n",
        "        \n",
        "        # Build k-word states\n",
        "        for i in range(len(tokens) - self.k):\n",
        "            if self.k == 1:\n",
        "                # Single word state (original implementation)\n",
        "                current_state = tokens[i]\n",
        "            else:\n",
        "                # Multi-word state (tuple)\n",
        "                current_state = tuple(tokens[i:i+self.k])\n",
        "            \n",
        "            next_word = tokens[i + self.k]\n",
        "            term_dict[current_state].append(next_word)\n",
        "        \n",
        "        self.term_dict = dict(term_dict)\n",
        "        return self.term_dict\n",
        "    \n",
        "    def generate(self, seed_term=None, term_count=15):\n",
        "        \"\"\"\n",
        "        Generate text using k-word Markov states.\n",
        "        \n",
        "        Parameters:\n",
        "        - seed_term: starting word(s). Can be a string (for k=1) or tuple (for k>1)\n",
        "        - term_count: number of words to generate\n",
        "        \"\"\"\n",
        "        import numpy as np\n",
        "        import random\n",
        "        \n",
        "        if self.term_dict is None:\n",
        "            self.get_term_dict()\n",
        "        \n",
        "        # Handle seed term based on k value\n",
        "        if seed_term is None:\n",
        "            # Choose random starting state - use random.choice for complex objects\n",
        "            current_state = random.choice(list(self.term_dict.keys()))\n",
        "        else:\n",
        "            # Validate and set seed term\n",
        "            if self.k == 1:\n",
        "                if seed_term not in self.term_dict:\n",
        "                    raise ValueError(f\"Seed term '{seed_term}' not found in corpus\")\n",
        "                current_state = seed_term\n",
        "            else:\n",
        "                # For k>1, seed_term should be a tuple or we'll try to find a matching state\n",
        "                if isinstance(seed_term, str):\n",
        "                    # Find a state that starts with this word\n",
        "                    matching_states = [state for state in self.term_dict.keys() \n",
        "                                     if state[0] == seed_term]\n",
        "                    if not matching_states:\n",
        "                        raise ValueError(f\"No states found starting with '{seed_term}'\")\n",
        "                    current_state = random.choice(matching_states)\n",
        "                else:\n",
        "                    if seed_term not in self.term_dict:\n",
        "                        raise ValueError(f\"Seed state '{seed_term}' not found in corpus\")\n",
        "                    current_state = seed_term\n",
        "        \n",
        "        # Initialize generated words\n",
        "        if self.k == 1:\n",
        "            generated_words = [current_state]\n",
        "        else:\n",
        "            generated_words = list(current_state)\n",
        "        \n",
        "        # Generate subsequent words\n",
        "        for _ in range(term_count - self.k):\n",
        "            if current_state not in self.term_dict or len(self.term_dict[current_state]) == 0:\n",
        "                break\n",
        "            \n",
        "            # Choose next word - use numpy for lists\n",
        "            next_word = np.random.choice(self.term_dict[current_state])\n",
        "            generated_words.append(next_word)\n",
        "            \n",
        "            # Update current state for next iteration\n",
        "            if self.k == 1:\n",
        "                current_state = next_word\n",
        "            else:\n",
        "                # Slide the window: remove first word, add new word\n",
        "                current_state = current_state[1:] + (next_word,)\n",
        "        \n",
        "        return ' '.join(generated_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "dd6d0e6f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Bonus Exercise: Comparing k-word State Windows ===\n",
            "\n",
            "üîπ k=1 (using 1-word state):\n",
            "   Dictionary size: 994 states\n",
            "   Sample states:\n",
            "     'Healing' ‚Üí ['comes']...\n",
            "     'comes' ‚Üí ['from', 'from']...\n",
            "     'from' ‚Üí ['taking', 'aesthetic', 'a']...\n",
            "   Generated text (25 words):\n",
            "     expression and easy way. Standing for they will simply what you‚Äôre doing is not have peace with that most frightens us. It turns what is\n",
            "\n",
            "üîπ k=2 (using 2-word states):\n",
            "   Dictionary size: 2150 states\n",
            "   Sample states:\n",
            "     ('Healing', 'comes') ‚Üí ['from']...\n",
            "     ('comes', 'from') ‚Üí ['taking', 'not']...\n",
            "     ('from', 'taking') ‚Üí ['responsibility:']...\n",
            "   Generated text (25 words):\n",
            "     doing is in everyone. And as we let our light shine, we unconsciously give other people around you won‚Äôt feel insecure. We are all meant\n",
            "\n",
            "üîπ k=3 (using 3-word states):\n",
            "   Dictionary size: 2454 states\n",
            "   Sample states:\n",
            "     ('Healing', 'comes', 'from') ‚Üí ['taking']...\n",
            "     ('comes', 'from', 'taking') ‚Üí ['responsibility:']...\n",
            "     ('from', 'taking', 'responsibility:') ‚Üí ['to']...\n",
            "   Generated text (25 words):\n",
            "     past, worry about the future, or anticipate troubles, but to live in the present moment wisely and earnestly. True happiness is not attained through self-gratification,\n",
            "\n",
            "üîç Observations:\n",
            "‚Ä¢ k=1: More random, less coherent (each word depends on only 1 previous word)\n",
            "‚Ä¢ k=2: More coherent phrases (each word depends on 2 previous words)\n",
            "‚Ä¢ k=3: Most coherent but potentially more repetitive (depends on 3 previous words)\n",
            "‚Ä¢ Higher k values require larger corpuses to avoid dead ends\n"
          ]
        }
      ],
      "source": [
        "# Test the enhanced Markov text generator with different k values\n",
        "print(\"=== Bonus Exercise: Comparing k-word State Windows ===\")\n",
        "print()\n",
        "\n",
        "# Test with k=1, 2, and 3\n",
        "k_values = [1, 2, 3]\n",
        "term_count = 25\n",
        "\n",
        "for k in k_values:\n",
        "    print(f\"üîπ k={k} (using {k}-word state{'s' if k > 1 else ''}):\")\n",
        "    \n",
        "    # Create generator with k-word states\n",
        "    enhanced_gen = EnhancedMarkovText(corpus, k=k)\n",
        "    term_dict = enhanced_gen.get_term_dict()\n",
        "    \n",
        "    print(f\"   Dictionary size: {len(term_dict)} states\")\n",
        "    \n",
        "    # Show sample dictionary entries\n",
        "    sample_keys = list(term_dict.keys())[:3]\n",
        "    print(\"   Sample states:\")\n",
        "    for key in sample_keys:\n",
        "        if k == 1:\n",
        "            print(f\"     '{key}' ‚Üí {term_dict[key][:3]}...\")\n",
        "        else:\n",
        "            print(f\"     {key} ‚Üí {term_dict[key][:3]}...\")\n",
        "    \n",
        "    # Generate text\n",
        "    print(f\"   Generated text ({term_count} words):\")\n",
        "    generated_text = enhanced_gen.generate(term_count=term_count)\n",
        "    print(f\"     {generated_text}\")\n",
        "    \n",
        "    print()\n",
        "\n",
        "print(\"üîç Observations:\")\n",
        "print(\"‚Ä¢ k=1: More random, less coherent (each word depends on only 1 previous word)\")\n",
        "print(\"‚Ä¢ k=2: More coherent phrases (each word depends on 2 previous words)\")  \n",
        "print(\"‚Ä¢ k=3: Most coherent but potentially more repetitive (depends on 3 previous words)\")\n",
        "print(\"‚Ä¢ Higher k values require larger corpuses to avoid dead ends\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "425ceb9f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Coherence Comparison: All Starting with 'life' ===\n",
            "\n",
            "k=1: life is life, fight for they shall become YOUR DESTINY. Wisdom is nothing to share of us grateful, but our\n",
            "\n",
            "k=2: life to be true. I am bound to live in the way things are. When you realize you contain what\n",
            "\n",
            "k=3: life by what we get, we make a life by what we give. Money doesn‚Äôt bring happiness and creativity. Your\n",
            "\n",
            "üìä Analysis:\n",
            "‚Ä¢ k=1: Chaotic jumps between topics\n",
            "‚Ä¢ k=2: Better flow and more natural phrases\n",
            "‚Ä¢ k=3: Most coherent and grammatically correct sentences\n",
            "‚Ä¢ Trade-off: Higher k = more coherent but potentially more repetitive\n"
          ]
        }
      ],
      "source": [
        "# Compare text coherence with the same starting word\n",
        "print(\"=== Coherence Comparison: All Starting with 'life' ===\")\n",
        "print()\n",
        "\n",
        "seed_word = \"life\"\n",
        "for k in [1, 2, 3]:\n",
        "    print(f\"k={k}: \", end=\"\")\n",
        "    enhanced_gen = EnhancedMarkovText(corpus, k=k)\n",
        "    enhanced_gen.get_term_dict()\n",
        "    \n",
        "    try:\n",
        "        result = enhanced_gen.generate(seed_term=seed_word, term_count=20)\n",
        "        print(result)\n",
        "    except ValueError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "    print()\n",
        "\n",
        "print(\"üìä Analysis:\")\n",
        "print(\"‚Ä¢ k=1: Chaotic jumps between topics\")\n",
        "print(\"‚Ä¢ k=2: Better flow and more natural phrases\")  \n",
        "print(\"‚Ä¢ k=3: Most coherent and grammatically correct sentences\")\n",
        "print(\"‚Ä¢ Trade-off: Higher k = more coherent but potentially more repetitive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79d9f48b",
      "metadata": {},
      "source": [
        "## üéâ Bonus Exercise Complete!\n",
        "\n",
        "### Key Achievements:\n",
        "1. **Extended the Markov model** from single-word states to k-word states\n",
        "2. **Implemented tuple-based state transitions** for multi-word contexts\n",
        "3. **Demonstrated improved text coherence** with higher k values\n",
        "4. **Showed the trade-offs** between coherence and diversity\n",
        "\n",
        "### Technical Implementation:\n",
        "- **k=1**: Traditional single-word Markov chains `\"word\" ‚Üí [\"next1\", \"next2\", ...]`\n",
        "- **k=2**: Two-word context states `(\"word1\", \"word2\") ‚Üí [\"next1\", \"next2\", ...]` \n",
        "- **k=3**: Three-word context states for maximum coherence\n",
        "\n",
        "### Results Summary:\n",
        "- **Higher k values produce more coherent text** but require larger training corpora\n",
        "- **k=3 generates the most natural-sounding sentences** in our tests\n",
        "- **The sliding window approach** maintains context throughout generation\n",
        "- **Error handling** gracefully manages missing states and invalid seeds\n",
        "\n",
        "This demonstrates how increasing the \"memory\" of a Markov chain dramatically improves the quality of generated text while maintaining the probabilistic nature of the model!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
